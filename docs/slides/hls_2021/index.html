<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Using intonation to disambiguate meaning: The role of empathy and proficiency in L2 perceptual development</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link href="libs/remark-css/rutgers.css" rel="stylesheet" />
    <link href="libs/remark-css/rutgers-fonts.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Using intonation to disambiguate meaning:<br>The role of empathy and proficiency in L2 perceptual development
### <p>Joseph V. Casillas, Juan José Garrido Puzó, Nicole Rodríguez, Kyle Parrish, Laura Fernández Arroyo, Robert Esposito, Isabelle Chang, Kimberly Gómez, Constantin-Dureci, Jaiwei Shao, Iván Rascón &amp; Katherine Taveras</p>
### Rutgers University
### HLS 2021

---










class: center
count: false
background-image: url(./libs/img/osf_dark.png), url(./libs/img/open_data.png), url(./libs/img/open_materials.png), url(./libs/img/prereg.png), url(./libs/img/qr4.png)
background-size: 100px, 100px, 100px, 100px, 110px
background-position: 20% 70%, 35% 70%, 50% 70%, 65% 70%, 80% 70%


# &lt;br&gt;&lt;br&gt;.grey[Slides, data, code, and pre-print available]

### https://osf.io/cp9bs/

---
exclude: true

# Summary 

- ADD ABSTRACT LIKE SUMMARY HERE

---

# Background

.big[
&lt;ul class="no_bullet"&gt;
&lt;li class="prod"&gt;INFO HERE&lt;br&gt;INFO HERE&lt;br&gt;INFO HERE&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
]

&lt;/br&gt;
&lt;/br&gt;
&lt;/br&gt;


.big[
&lt;ul class="no_bullet"&gt;
&lt;li class="perc"&gt;INFO HERE&lt;br&gt;INFO HERE&lt;br&gt;INFO HERE&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;
]

---

# The big picture

&lt;/br&gt;

.big[
- Unclear how dynamic perceptual categorization develops and whether or 
not it can be conceptually cued in late bilinguals
]

--

.big[
- We did a conceptual replication of 

]

--

.big[
- We tested the extent to which adult second language (L2) learners of Spanish 
modulated their identification of a resynthesized voice timing continuum based 
on the language they believed they were hearing.
]

---
class: title-slide-section-grey, middle

# .RUred[Research questions]

.big[
QUESTIONS HERE
]

---
class: title-slide-section-red, middle

# Method

---
background-image: url(https://raw.githubusercontent.com/jvcasillas/media/master/linguistics/img/perception_2.png)
background-size: 150px
background-position: 90% 20%

# Method

### Participants

.large[
- We recruited participants (n = 224) for a 
two-alternative &lt;/br&gt; forced choice (2AFC) task and lexical decision task
]

--

### Proficiency

.large[
- All participants completed LexTALE-ESP&lt;sup&gt;1&lt;/sup&gt;
- Lexical decision task, assessment of vocab size/proficiency
- x&amp;#772; &amp;equals; 
NUM &amp;pm;
NUM SD, range [
NUM, NUM]
]

.footnote[&lt;sup&gt;1&lt;/sup&gt;]

???

Online-recruited participants were restricted to monolingual English speakers 
born, raised, and currently living in the United States with no knowledge of 
any languages other than English.

Participants responded to the following screening questions: 1) *Was English 
your first language?*, 2) *Did you start learning Spanish at the age of 13 or 
older?*, and 3) *Do you have significant knowledge of any languages besides 
English and Spanish?*.

We excluded data from participants responding "no" to (1) or (2), or "yes" 
to (3).

---
background-image: url(../../manuscript/includes/figs/lextale/plot_lextale.png)
background-size: 100%

???

Lexical Test for Advanced Learners of Spanish as a standardized assessment of 
participants' proficiency/vocabulary size in Spanish.

scores can range from &amp;minus;20 to 60, with native speaker values generally 
found between 50-60.

Individuals with little or no knowledge of Spanish typically score from 
&amp;minus;20 to 0.

proficiency is treated as a continuous  variable, thus we consider a 
monolingual English speaker to have little to no proficiency in Spanish.

Min. &amp;equals; 
NUM, Max. &amp;equals;
NUM

mean &amp;equals; 
NUM (95% CI: [
NUM, 
NUM])  
SD &amp;equals;
NUM

---
background-image: url(./libs/img/ins_sp.png)
background-size: 500px
background-position: 95% 50%

# Method

### Instructions

- Recorded in English by 25-year-old female &lt;br&gt;Spanish-English 
simultaneous bilingual &lt;br&gt;(duration &amp;equals; 35 s)

- Two sets, one for each language context &lt;br&gt;(.blue[Spanish], **English**)

- Conceptually cued context by telling participants &lt;br&gt;they would hear 
fragments of rare words in Spanish &lt;br&gt;or English

- Recordings did not mention orally the target words, &lt;br&gt;only presented 
orthographically

- Recordings were identical in content and acoustic &lt;br&gt;information in all ways 
except for the words "English" &lt;br&gt;and "Spanish".

---

# Method

### Stimuli

&lt;div style="float:right"&gt;
.full-width[
.content-box-blue[
&lt;audio controls style="width: 120px;"&gt;
  &lt;source src="./libs/wav/pa-35.ogg" type="audio/ogg"&gt;
  &lt;source src="./libs/wav/pa-35.wav" type="audio/mpeg"&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;/br&gt;
&lt;audio controls style="width: 120px;"&gt;
  &lt;source src="./libs/wav/pa+35.ogg" type="audio/ogg"&gt;
  &lt;source src="./libs/wav/pa+35.wav" type="audio/mpeg"&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
]
]
&lt;/div&gt;

- Pseudoword VOT continuum .lightgrey[]
- 14 stop &amp;#43; [af] sequences 
- VOT from &amp;minus;35 to 35 ms in 5 ms increments (excluding 0)

### Procedure

- 2 separate testing sessions with different language contexts
  - Session 1: first iteration of the 2AFC task, followed by the LexTALE task
  - Session 2: second iteration of the 2AFC task
- Language context counter balanced across participants
- Stimuli drawn randomly from VOT continuum in 10 separate blocks 
(14 steps &amp;times; 10 blocks &amp;equals; 140 responses per participant).
- Experiments run in PsychoPy3 .lightgrey[(Peirce et al., 2019)] 

---

# Method 

### Statistical analysis

- Bayesian multilevel regression model fitted in `stan` using `brms` 
.lightgrey[]

- Responses, 'bafri'/'pafri', coded as 0/1

- Modeled as a function of *VOT*, *context* (English, Spanish), 
*LexTALE score*,  and all higher order interactions

- Continuous predictors standardized and language context was
deviation coded &lt;br&gt;(Spanish = &amp;minus;0.5, English = 0.5)

- By-subject intercepts with random slopes for *VOT*, *context*, 
*LexTALE score*, and all higher order interactions

- 2000 iterations (1000 warm-up), 16 processing cores 

- Regularizing, weakly informative priors .lightgrey[]

---
class: title-slide-section-red, middle

# Results

---
background-image: url(../../manuscript/includes/figs/2afc/plot_2afc_mod.png)
background-size: 100%

---
background-image: url(../../manuscript/includes/figs/2afc/plot_2afc_3way_posterior.png)
background-size: 100%

---
background-image: url(./libs/img/plot_2afc_3way_triptych_1.png)
background-size: 100%

---
count: false
background-image: url(./libs/img/plot_2afc_3way_triptych_2.png)
background-size: 100%

---
count: false
background-image: url(./libs/img/plot_2afc_3way_triptych_3.png)
background-size: 100%

---
# Review

.Large[
- We conceptually cued language context in a within subjects design
]

--

.Large[
- We replicated the DPBE, extend it to a different population: &lt;/br&gt;adult L2 
learners
]

--

&lt;p&gt;&lt;/p&gt;

.Large[
- Support for theoretically motivated 3-way interaction between VOT, 
proficiency, and language context
  - Low proficiency = 'voiceless' responses varied as a function of VOT 
  - Higher proficiency = more likely to respond 'voiceless' when they were led 
  to believe they were hearing Spanish
]

---

# Discussion

.pull-left[

### Corroborates "language set" experiments

.full-width[
.content-box-blue[

Perceptual categorization depends on language context in monolingual 
language mode in early bilinguals&lt;sup&gt;1&lt;/sup&gt; and in late bilinguals&lt;sup&gt;2&lt;/sup&gt; 

]
]
]

.pull-right[

### Selective activation accounts

.full-width[
.content-box-blue[

- Support SA of independent perception grammars in L2 learning
- L2LP interpretation of Grosjean's language mode hypothesis:  
ability to activate L1/L2 perception grammars develops w/ exposure to L2  
.blue[What is exposure?]
]
]
]

.footnote[
.tiny[
&lt;sup&gt;1&lt;/sup&gt;  
&lt;sup&gt;2&lt;/sup&gt;
]
]

---

# Discussion

### Exposure

.large[
- L2LP posits TL exposure as the driving force behind meaning-driven learning 
vis-à-vis the perception grammar .lightgrey[]
]

--

.large[
&lt;p&gt;&lt;/p&gt;
- How do you operationalize/quantify exposure?
  - Phonological development is correlated with L2 vocabulary size  
  .lightgrey[]
  - Largest gains often occur at an early stage of development  
  .lightgrey[]
]

---
background-image: url(../../manuscript/includes/figs/dag/plot_dag.png)
background-size: 550px
background-position: 92% 50%

# Discussion

### Exposure

.pull-left[
.large[
- Multiple paths to development of L2 perceptual grammar?

- Perhaps proficiency, vocabulary size, quantity/quality of 
input (or a combination) are key to perceptual development

]
]

.full-width[
.content-box-blue[

**Future research**: measure and control for input and vocabulary size in 
conjunction with standardized measures of proficiency to tease apart how these 
variables interact during L2 perceptual development to better inform models 
of L2 speech learning
]
]

???

A directed acyclic graph (DAG) illustrating possible causal paths from input 
(I), vocabulary size (V), and proficiency (P) to perceptual development (PD). 
The curved line indicates a bidirectional relationship.

future research relates to how the model conceives of L2 development

L2LP posits TL exposure as the driving force behind meaning-driven learning 
vis-à-vis the perception grammar[@VanLeussen2015, p. 4]. 

Perception improves if current state of the grammar results in 
misunderstandings; but no straightforward method for operationalizing nor 
quantifying exposure

phonological development is correlated with L2 vocabulary size 
[@bundgaard2012second]

learners' largest gains often occur at an early stage of development 
[@williams1979modification; @munro2012english]

standardized assessment of vocabulary size as a proxy to L2 proficiency.

The evidence provided herein cannot partial out the possible mediating effect 
of either

It may be the case that proficiency, vocabulary size, quantity and quality of 
input, or any combination thereof are the key to perceptual development

For instance, an individual could receive large amounts of L2 input and not 
improve in L2 proficiency

The converse is also true.

multiple paths to development of the L2 perceptual grammar?

A case could be made, for instance, that input, vocabulary size, or some 
version of the construct 'proficiency' could lead to perceptual development. 
However, at this time we cannot discount the possibility that vocabulary size 
or proficiency are also mediator variables associated with input. 
Future investigations should consider measuring and controlling for input 
and vocabulary size in conjunction with standardized measures of proficiency 
in order to shed light on how these variables interact during L2 perceptual 
development to better inform models of L2 speech learning. 
This also opens the door to new avenues for research on individual differences 
in the development of the L2 perception grammar.

---
class: middle

.Large[
.center[

|  .white[...............] | Acoustically&lt;/br&gt;cued          |    | Conceptually&lt;/br&gt;cued  |
| :----------------------- | :----------------------------: | :- | :--------------------: |
| .grey[Early&lt;/br&gt;learner] |  |    | Gonzales et al. (2019) |
| .grey[Late&lt;/br&gt;learner]  |  |    | .RUred[&amp;#10004;]       |

]
]

--

&lt;br&gt;

.center[
### **Conceptually cued language-specific processing routines in bilingual mode**?

![:scale 75%](./libs/img/language_modes.png)
]

---

# Conclusion

&lt;br&gt;

.large[
- We replicated the findings of Gonzales et al. (2019) and provided 
empirical evidence for conceptually-cued language mode selection in late 
bilinguals

- Adult L2 learners of Spanish also display mode-specific perceptual 
normalization criteria in accordance with the fine-phonetic detail of the 
language they have been led to believe they are hearing

- The DPBE develops as proficiency in the L2 increases

- Evidence supporting the notion that there is some degree of separation 
between phonetic systems in the bilingual mind
]

---
count: false
class: title-slide-final
background-image: url(https://github.com/jvcasillas/ru_xaringan/raw/master/img/logo/ru_shield.png), url(./libs/img/qr3.png), url(https://raw.githubusercontent.com/jvcasillas/hex_stickers/master/stickers/rap-group.png)
background-size: 100px, 150px, 130px
background-position: 25% 50%, 50% 50%, 75% 50%

&lt;br&gt;

# Thank you!

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

.large[

|                                     |                                         |
| ----------------------------------: | :-------------------------------------- |
| <svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg> | .lightgrey[joseph.casillas@rutgers.edu] |
| <svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>     | .lightgrey[@jvcasill]                   |
| <svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:red;overflow:visible;position:relative;"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg>        | .lightgrey[bit.ly/caspslap_2020]        |

]

---

# References


```
## You haven't cited any references in this bibliography yet.
```

NULL

---
count: false

# References II


```
## You haven't cited any references in this bibliography yet.
```

NULL

---
count: false

# References III


```
## You haven't cited any references in this bibliography yet.
```

NULL

---
count: false

# References IV


```
## You haven't cited any references in this bibliography yet.
```

NULL



&lt;style type="text/css"&gt;

/* H1 fonts */
.title-slide h1 {
  color: #cc0033;
  padding-top: 250px;
  font-weight: normal;
  font-size: 45px;
  text-align: left;
  text-shadow: none;
  padding-bottom: 18px;
  margin-bottom: 18px;
}

.remark-slide table {
  margin: auto;
  border: 0px none;
  border-collapse: collapse;
}
.remark-slide table thead th { 
  border: 0px none;
  background-color: none;
}

th, td { 
  padding: 5px;
  border: 0px none;
  background-color: none;
}

.remark-slide thead, .remark-slide tfoot, .remark-slide tr:nth-child(even) {
  border: 0px none;
  background: none;
}

ul.no_bullet {
  list-style-type: none;
  padding: 0;
  margin: 0;
}

li.prod {
  background: url(https://raw.githubusercontent.com/jvcasillas/media/master/linguistics/img/production_1.png) no-repeat;
  background-size: 95px 95px;
  display: block;
  padding: 0 50px 10px 150px;
}

li.perc {
  background: url(https://raw.githubusercontent.com/jvcasillas/media/master/linguistics/img/perception_1.png) no-repeat;
  background-size: 80px 95px;
  display: block;
  padding: 0 50px 10px 150px;
}

&lt;/style&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js"></script>
<script src="https://www.jvcasillas.com/ru_xaringan/js/ru_xaringan.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
