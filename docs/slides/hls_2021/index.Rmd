---
title: "Using intonation to disambiguate meaning:<br>The role of empathy and proficiency in L2 perceptual development"
author: |
  Joseph V. Casillas, Juan José Garrido Puzó, Nicole Rodríguez, Kyle Parrish, 
  Laura Fernández Arroyo, Robert Esposito, Isabelle Chang, Kimberly Gómez, 
  Constantin-Dureci, Jaiwei Shao, Iván Rascón & Katherine Taveras
institute: "Rutgers University"
date: "HLS 2021"
output:
  xaringan::moon_reader:
    chakra: "https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js"
    lib_dir: libs
    css: [default, hygge, rutgers, rutgers-fonts]
    nature:
      beforeInit: ["https://www.jvcasillas.com/ru_xaringan/js/ru_xaringan.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
    includes:
      in_header: "./libs/partials/header.html"
---



```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r, 'source-libs', message=F, echo=F}
source(here::here("scripts", "r", "12_small_data.R"))
library("fontawesome")
```

```{r, 'bib-setup', echo=F, warning=F, message=F}
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
bib <- ReadBib(here("docs", "bib", "empathy.bib"), check = FALSE)
```

class: center
count: false
background-image: url(./libs/img/osf_dark.png), url(./libs/img/open_data.png), url(./libs/img/open_materials.png), url(./libs/img/prereg.png), url(./libs/img/qr4.png)
background-size: 100px, 100px, 100px, 100px, 110px
background-position: 20% 70%, 35% 70%, 50% 70%, 65% 70%, 80% 70%


# <br><br>.grey[Slides, data, code, and pre-print available]

### https://osf.io/cp9bs/

---
exclude: true

# Summary 

- ADD ABSTRACT LIKE SUMMARY HERE

---

# Background

.big[
<ul class="no_bullet">
<li class="prod">INFO HERE<br>INFO HERE<br>INFO HERE<br></li>
</ul>
]

</br>
</br>
</br>


.big[
<ul class="no_bullet">
<li class="perc">INFO HERE<br>INFO HERE<br>INFO HERE<br></li>
</ul>
]

---

# The big picture

</br>

.big[
- Unclear how dynamic perceptual categorization develops and whether or 
not it can be conceptually cued in late bilinguals
]

--

.big[
- We did a conceptual replication of 
`r Citet(bib, "gonzales2019")`
]

--

.big[
- We tested the extent to which adult second language (L2) learners of Spanish 
modulated their identification of a resynthesized voice timing continuum based 
on the language they believed they were hearing.
]

---
class: title-slide-section-grey, middle

# .RUred[Research questions]

.big[
QUESTIONS HERE
]

---
class: title-slide-section-red, middle

# Method

---
background-image: url(https://raw.githubusercontent.com/jvcasillas/media/master/linguistics/img/perception_2.png)
background-size: 150px
background-position: 90% 20%

# Method

### Participants

.large[
- We recruited participants (n = `r n_learners`) for a 
two-alternative </br> forced choice (2AFC) task and lexical decision task
]

--

### Proficiency

.large[
- All participants completed LexTALE-ESP<sup>1</sup>
- Lexical decision task, assessment of vocab size/proficiency
- x&#772; &equals; 
NUM &pm;
NUM SD, range [
NUM, NUM]
]

.footnote[<sup>1</sup>`r Citet(bib, c("lextale_study", "lextale_esp"))`]

???

Online-recruited participants were restricted to monolingual English speakers 
born, raised, and currently living in the United States with no knowledge of 
any languages other than English.

Participants responded to the following screening questions: 1) *Was English 
your first language?*, 2) *Did you start learning Spanish at the age of 13 or 
older?*, and 3) *Do you have significant knowledge of any languages besides 
English and Spanish?*.

We excluded data from participants responding "no" to (1) or (2), or "yes" 
to (3).

---
background-image: url(../../manuscript/includes/figs/lextale/plot_lextale.png)
background-size: 100%

???

Lexical Test for Advanced Learners of Spanish as a standardized assessment of 
participants' proficiency/vocabulary size in Spanish.

scores can range from &minus;20 to 60, with native speaker values generally 
found between 50-60.

Individuals with little or no knowledge of Spanish typically score from 
&minus;20 to 0.

proficiency is treated as a continuous  variable, thus we consider a 
monolingual English speaker to have little to no proficiency in Spanish.

Min. &equals; 
NUM, Max. &equals;
NUM

mean &equals; 
NUM (95% CI: [
NUM, 
NUM])  
SD &equals;
NUM

---
background-image: url(./libs/img/ins_sp.png)
background-size: 500px
background-position: 95% 50%

# Method

### Instructions

- Recorded in English by 25-year-old female <br>Spanish-English 
simultaneous bilingual <br>(duration &equals; 35 s)

- Two sets, one for each language context <br>(.blue[Spanish], **English**)

- Conceptually cued context by telling participants <br>they would hear 
fragments of rare words in Spanish <br>or English

- Recordings did not mention orally the target words, <br>only presented 
orthographically

- Recordings were identical in content and acoustic <br>information in all ways 
except for the words "English" <br>and "Spanish".

---

# Method

### Stimuli

<div style="float:right">
.full-width[
.content-box-blue[
<audio controls style="width: 120px;">
  <source src="./libs/wav/pa-35.ogg" type="audio/ogg">
  <source src="./libs/wav/pa-35.wav" type="audio/mpeg">
Your browser does not support the audio element.
</audio>
</br>
<audio controls style="width: 120px;">
  <source src="./libs/wav/pa+35.ogg" type="audio/ogg">
  <source src="./libs/wav/pa+35.wav" type="audio/mpeg">
Your browser does not support the audio element.
</audio>
]
]
</div>

- Pseudoword VOT continuum .lightgrey[`r Citep(bib, "gonzales2019")`]
- 14 stop &#43; [af] sequences 
- VOT from &minus;35 to 35 ms in 5 ms increments (excluding 0)

### Procedure

- 2 separate testing sessions with different language contexts
  - Session 1: first iteration of the 2AFC task, followed by the LexTALE task
  - Session 2: second iteration of the 2AFC task
- Language context counter balanced across participants
- Stimuli drawn randomly from VOT continuum in 10 separate blocks 
(14 steps &times; 10 blocks &equals; 140 responses per participant).
- Experiments run in PsychoPy3 .lightgrey[(Peirce et al., 2019)] `r NoCite(bib, "Peirce:2019")`

---

# Method 

### Statistical analysis

- Bayesian multilevel regression model fitted in `stan` using `brms` 
.lightgrey[`r Citep(bib, "R_brms_a")`]

- Responses, 'bafri'/'pafri', coded as 0/1

- Modeled as a function of *VOT*, *context* (English, Spanish), 
*LexTALE score*,  and all higher order interactions

- Continuous predictors standardized and language context was
deviation coded <br>(Spanish = &minus;0.5, English = 0.5)

- By-subject intercepts with random slopes for *VOT*, *context*, 
*LexTALE score*, and all higher order interactions

- 2000 iterations (1000 warm-up), 16 processing cores 

- Regularizing, weakly informative priors .lightgrey[`r Citep(bib, "Gelman_2017")`]

---
class: title-slide-section-red, middle

# Results

---
background-image: url(../../manuscript/includes/figs/2afc/plot_2afc_mod.png)
background-size: 100%

---
background-image: url(../../manuscript/includes/figs/2afc/plot_2afc_3way_posterior.png)
background-size: 100%

---
background-image: url(./libs/img/plot_2afc_3way_triptych_1.png)
background-size: 100%

---
count: false
background-image: url(./libs/img/plot_2afc_3way_triptych_2.png)
background-size: 100%

---
count: false
background-image: url(./libs/img/plot_2afc_3way_triptych_3.png)
background-size: 100%

---
# Review

.Large[
- We conceptually cued language context in a within subjects design
]

--

.Large[
- We replicated the DPBE, extend it to a different population: </br>adult L2 
learners
]

--

<p></p>

.Large[
- Support for theoretically motivated 3-way interaction between VOT, 
proficiency, and language context
  - Low proficiency = 'voiceless' responses varied as a function of VOT 
  - Higher proficiency = more likely to respond 'voiceless' when they were led 
  to believe they were hearing Spanish
]

---

# Discussion

.pull-left[

### Corroborates "language set" experiments

.full-width[
.content-box-blue[

Perceptual categorization depends on language context in monolingual 
language mode in early bilinguals<sup>1</sup> and in late bilinguals<sup>2</sup> 

]
]
]

.pull-right[

### Selective activation accounts

.full-width[
.content-box-blue[

- Support SA of independent perception grammars in L2 learning
- L2LP interpretation of Grosjean's language mode hypothesis:  
ability to activate L1/L2 perception grammars develops w/ exposure to L2  
.blue[What is exposure?]
]
]
]

.footnote[
.tiny[
<sup>1</sup>`r Citet(bib, c("elman1977", "williams1977", "flege1987", 
"bohn1993", "hazan1993", "garcia_sierra2009", "garcia_sierra2012"))`  
<sup>2</sup>`r Citet(bib, "casillas2018")`
]
]

---

# Discussion

### Exposure

.large[
- L2LP posits TL exposure as the driving force behind meaning-driven learning 
vis-à-vis the perception grammar .lightgrey[`r Citep(bib, "VanLeussen2015")`]
]

--

.large[
<p></p>
- How do you operationalize/quantify exposure?
  - Phonological development is correlated with L2 vocabulary size  
  .lightgrey[`r Citep(bib, "bundgaard2012second")`]
  - Largest gains often occur at an early stage of development  
  .lightgrey[`r Citep(bib, c("williams1979modification", "munro2012english"))`]
]

---
background-image: url(../../manuscript/includes/figs/dag/plot_dag.png)
background-size: 550px
background-position: 92% 50%

# Discussion

### Exposure

.pull-left[
.large[
- Multiple paths to development of L2 perceptual grammar?

- Perhaps proficiency, vocabulary size, quantity/quality of 
input (or a combination) are key to perceptual development

]
]

.full-width[
.content-box-blue[

**Future research**: measure and control for input and vocabulary size in 
conjunction with standardized measures of proficiency to tease apart how these 
variables interact during L2 perceptual development to better inform models 
of L2 speech learning
]
]

???

A directed acyclic graph (DAG) illustrating possible causal paths from input 
(I), vocabulary size (V), and proficiency (P) to perceptual development (PD). 
The curved line indicates a bidirectional relationship.

future research relates to how the model conceives of L2 development

L2LP posits TL exposure as the driving force behind meaning-driven learning 
vis-à-vis the perception grammar[@VanLeussen2015, p. 4]. 

Perception improves if current state of the grammar results in 
misunderstandings; but no straightforward method for operationalizing nor 
quantifying exposure

phonological development is correlated with L2 vocabulary size 
[@bundgaard2012second]

learners' largest gains often occur at an early stage of development 
[@williams1979modification; @munro2012english]

standardized assessment of vocabulary size as a proxy to L2 proficiency.

The evidence provided herein cannot partial out the possible mediating effect 
of either

It may be the case that proficiency, vocabulary size, quantity and quality of 
input, or any combination thereof are the key to perceptual development

For instance, an individual could receive large amounts of L2 input and not 
improve in L2 proficiency

The converse is also true.

multiple paths to development of the L2 perceptual grammar?

A case could be made, for instance, that input, vocabulary size, or some 
version of the construct 'proficiency' could lead to perceptual development. 
However, at this time we cannot discount the possibility that vocabulary size 
or proficiency are also mediator variables associated with input. 
Future investigations should consider measuring and controlling for input 
and vocabulary size in conjunction with standardized measures of proficiency 
in order to shed light on how these variables interact during L2 perceptual 
development to better inform models of L2 speech learning. 
This also opens the door to new avenues for research on individual differences 
in the development of the L2 perception grammar.

---
class: middle

.Large[
.center[

|  .white[...............] | Acoustically</br>cued          |    | Conceptually</br>cued  |
| :----------------------- | :----------------------------: | :- | :--------------------: |
| .grey[Early</br>learner] | `r Citet(bib, "gonzales2013")` |    | Gonzales et al. (2019) |
| .grey[Late</br>learner]  | `r Citet(bib, "casillas2018")` |    | .RUred[&#10004;]       |

]
]

--

<br>

.center[
### **Conceptually cued language-specific processing routines in bilingual mode**?

![:scale 75%](./libs/img/language_modes.png)
]

---

# Conclusion

<br>

.large[
- We replicated the findings of Gonzales et al. (2019) and provided 
empirical evidence for conceptually-cued language mode selection in late 
bilinguals

- Adult L2 learners of Spanish also display mode-specific perceptual 
normalization criteria in accordance with the fine-phonetic detail of the 
language they have been led to believe they are hearing

- The DPBE develops as proficiency in the L2 increases

- Evidence supporting the notion that there is some degree of separation 
between phonetic systems in the bilingual mind
]

---
count: false
class: title-slide-final
background-image: url(https://github.com/jvcasillas/ru_xaringan/raw/master/img/logo/ru_shield.png), url(./libs/img/qr3.png), url(https://raw.githubusercontent.com/jvcasillas/hex_stickers/master/stickers/rap-group.png)
background-size: 100px, 150px, 130px
background-position: 25% 50%, 50% 50%, 75% 50%

<br>

# Thank you!

<br><br><br><br><br><br><br><br><br><br><br>

.large[

|                                     |                                         |
| ----------------------------------: | :-------------------------------------- |
| `r fa("paper-plane", fill = "red")` | .lightgrey[joseph.casillas@rutgers.edu] |
| `r fa("twitter", fill = "red")`     | .lightgrey[@jvcasill]                   |
| `r fa("link", fill = "red")`        | .lightgrey[bit.ly/caspslap_2020]        |

]

---

# References

```{r, results='asis', echo=FALSE, warning=FALSE}
PrintBibliography(bib, start = 1, end = 6)
```

---
count: false

# References II

```{r, results='asis', echo=FALSE, warning=FALSE}
PrintBibliography(bib, start = 7, end = 12)
```

---
count: false

# References III

```{r, results='asis', echo=FALSE, warning=FALSE}
PrintBibliography(bib, start = 13, end = 18)
```

---
count: false

# References IV

```{r, results='asis', echo=FALSE, warning=FALSE}
PrintBibliography(bib, start = 19, end = 24)
```



<style type="text/css">

/* H1 fonts */
.title-slide h1 {
  color: #cc0033;
  padding-top: 250px;
  font-weight: normal;
  font-size: 45px;
  text-align: left;
  text-shadow: none;
  padding-bottom: 18px;
  margin-bottom: 18px;
}

.remark-slide table {
  margin: auto;
  border: 0px none;
  border-collapse: collapse;
}
.remark-slide table thead th { 
  border: 0px none;
  background-color: none;
}

th, td { 
  padding: 5px;
  border: 0px none;
  background-color: none;
}

.remark-slide thead, .remark-slide tfoot, .remark-slide tr:nth-child(even) {
  border: 0px none;
  background: none;
}

ul.no_bullet {
  list-style-type: none;
  padding: 0;
  margin: 0;
}

li.prod {
  background: url(https://raw.githubusercontent.com/jvcasillas/media/master/linguistics/img/production_1.png) no-repeat;
  background-size: 95px 95px;
  display: block;
  padding: 0 50px 10px 150px;
}

li.perc {
  background: url(https://raw.githubusercontent.com/jvcasillas/media/master/linguistics/img/perception_1.png) no-repeat;
  background-size: 80px 95px;
  display: block;
  padding: 0 50px 10px 150px;
}

</style>
