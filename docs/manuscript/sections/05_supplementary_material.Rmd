## Traditional analyses

This section contains additional information regarding the response accuracy and response time analyses, as well as tables reported but not included in the main text.

**Learner response accuracy**. 

The population effects of the response accuracy model were specified in the following manner: 

$$
\begin{aligned}
\text{is_correct}_{ij} &\sim Bernoulli\left(p_{ij}, m_{ij}\right) \\
\text{logit}\left(p_{ij}\right) &= \beta_{0} + \beta_{1} * question\_type + \beta_{2} * LexTALE + \beta_{3} * EQ + \\ 
 & \ \ \ \ \beta_{4} * question\_type * LexTALE * EQ 
\end{aligned}
$$

We employed the `0 + Intercept` syntax of `brms` and set weakly informative priors as follows: 

$$
\begin{aligned}
\beta  &\sim Normal(0, 0.3) \\
\sigma &\sim Cauchy(0, 0.1) \\
\rho   &\sim LKJcorr(2)
\end{aligned}
$$

The summary of the response accuracy model is available in Table \@ref(tab:table-learner-accuracy-by-utterance-type). 
The information provided in this table is equivalent to the left panel of Figure \@ref(fig:plot-learner-accuracy-forest-by-utterance-type) in the manuscript. 

```{r, 'table-learner-accuracy-by-utterance-type'}
read_csv(here("tables", "learner_response_01.csv"), col_types = cols(.default = "c")) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r", "r", "r"), 
    caption = "Summary of the posterior distribution modeling 
    response accuracy as a function of utterance type, LexTALE, and 
    Empathy quotient. The table includes posterior medians, the 95% HDI, 
    the percentage of the HDI within the ROPE, and the maximum probability 
    of effect (MPE).",
    label = "table-learner-accuracy-by-utterance-type")
```


```{=openxml}
<w:p><w:r><w:br w:type="page"/></w:r></w:p>
```


## Drift diffusion models

Drift Diffusion Models (DDM), also referred to as Wiener Diffusion Models and Decision Diffusion Models, represent our preferred method for analyzing the data from our 2AFC task. 
DDMs are rarely used in SLA research, though they are commonplace in psychology. 
The primary selling point of using a DDM is related to the parameters the model estimates: boundary separation (&alpha;), drift rate (&delta;), bias (&beta;), and non-decision time (&tau;). 
Together these parameters give rich information about the processes believed to underpin decision-making. 
Specifically, a DDM requires decision data, e.g., "left" or "right" choices, correct or incorrect responses, etc., and response times associated with said decisions. 
In linguistics, particularly in psycholinguistics, data of this nature derived from 2AFC tasks are often analyzed using separate models, one for responses, and another for response times (as we have done in our so-called 'traditional analyses').^[Given how relatively uncommon DDMs are in linguistics, the present work includes both approaches, though it is reasonable to assume that this practice will diminish as DDMs become more well-known and the resources for implementing them become more user-friendly.] 
As mentioned, a DDM uses both of these dependent variables---responses and response times---to estimate the 4 aforementioned parameters. 
The estimates can then be scrutinized in subsequent models, if one estimates the parameters for each participant (i.e., the approach taken in the present work), and/or used for simulations. 
For our purposes, we employ the Bayesian implementation of the DDM, thus we sample from a posterior distribution of plausible estimates for &alpha;, &delta;, &beta;, and &tau; for each participant. 
We then summarize and report these posterior distributions for statistical inferences. 

The no-pooling models were fit using the following specification in `brms`: 

```r
  rt_raw | dec(is_correct) ~ 0 + sentence_type,
  bs ~ 0 + sentence_type, 
  ndt ~ 0 + sentence_type, 
  bias ~ 0 + sentence_type
```

and the priors were: 

```r
prior("normal(0, 1)", class = "b"),
prior("normal(0, 5)", class = "b", dpar = "bs"),
prior("normal(0.2, 1)", class = "b", dpar = "ndt"),
prior("normal(0.5, 1)", class = "b", dpar = "bias")
```

The complete code used to fit the models are available in `09_ddm.R` in the r scripts directory. 

**Measurement-error models**. The measurement error models fit to the boundary separation and drift rate data were specified to include the standard error around each posterior median for &alpha; and &delta;: 

$$
\begin{split}
\alpha &\sim Normal\left(\alpha_{n,TRUE}, SE_{\alpha}\right) \\
\delta &\sim Normal(\delta_{n,TRUE}, SE_{\delta})
\end{split}
$$

The priors for the drift rate model were: 

$$
\begin{aligned}
\alpha &\sim Normal(1, 0.5) \\
\beta  &\sim Normal(0, 0.3)  \\
\tau   &\sim Cauchy(0, 0.3) \\
\sigma &\sim Cauchy(0, 0.1) \\
\rho   &\sim LKJcorr(2)
\end{aligned}
$$

and the priors for the boundary separation model were: 

$$
\begin{aligned}
\alpha &\sim Normal(2, 0.5) \\
\beta  &\sim Normal(0, 0.5)  \\
\tau   &\sim Cauchy(0, 0.3) \\
\sigma &\sim Cauchy(0, 0.1) \\
\rho   &\sim LKJcorr(2)
\end{aligned}
$$

To specify this type of model in `brms` we use the `resp_se` function, as follows: 

```r
estimate | resp_se(se, sigma = TRUE) ~ 1 + # Criterion
  q_sum * lextale_std * eq_std +           # Population-level effects
  (1 + q_sum * lextale_std * eq_std | participant) # Group-level effects
```


The model summary is available in Table \@ref(tab:table-ddm-bs-dr), which is equivalent to Figure \@ref(fig:plot-mem-bs-dr-estimates) in the main document. 

```{r, 'table-ddm-bs-dr'}
read_csv(here("tables", "ddm_bs_dr.csv"), col_types = cols(.default = "c")) %>% 
  mutate(Model = case_when(
    Model == "Boundary separation" & Parameter == "Intercept" ~ "Boundary", 
    Model == "Boundary separation" & Parameter == "Question type" ~ "separation", 
    Model == "Boundary separation" & !(Parameter %in% c("Intercept", "Question type")) ~ " ", 
    Model == "Drift rate" & Parameter == "Intercept" ~ "Drift rate", 
    Model == "Drift rate" & Parameter != "Intercept" ~ " ", 
  )) %>% 
  knitr::kable(format = "pandoc", align = c(rep("l", 2), rep("r", 5)), 
    caption = "Summary of the posterior distribution modeling 
    boundary separation and drift rate as a function of question type, 
    LexTALE, and Empathy quotient. The table includes posterior medians, 
    the 95% HDI, the percentage of the HDI within the ROPE, and the maximum 
    probability of effect (MPE).",
    label = "table-ddm-bs-dr")
```


```{=openxml}
<w:p><w:r><w:br w:type="page"/></w:r></w:p>
```


## Supplementary analyses {#supplementary-analyses}

In this section we present supplementary analyses, all of which are exploratory in nature. 

**D'**. Figure \@ref(fig:plot-learner-dp-utterance-variety) and Table \@ref(tab:table-dp-utterance-variety) represent an exploratory analysis of d' scores as a function of utterance type and speaker variety. 
One observes similar patterns to those from the accuracy analysis presented in the manuscript. 
The primary takeaway is that the analysis of learners' sensitivity to Spanish prosody mirrors that of their accuracy. 
That is to say, learners are more sensitive to (and accurate with) statements (broad focus, narrow focus) than questions (wh-, yes/no) (left panel of Figure \@ref(fig:plot-learner-dp-utterance-variety). 
Learner sensitivity to the different Spanish varieties represented in the stimuli pattern in the same manner, i.e., more sensitivity to the Peninsular variety and less sensitivity to the Cuban variety (right panel of Figure \@ref(fig:plot-learner-dp-utterance-variety)).
Table \@ref(tab:table-dp-utterance-variety) summarizes the posterior of these exploratory analyses. 

(ref:plot-learner-dp-utterance-variety) Exploratory analysis of d' as a function of utterance type and speaker variety. Points represent posterior medians &pm;66% and 95% credible intervals.

```{r, 'plot-learner-dp-utterance-variety', fig.cap="(ref:plot-learner-dp-utterance-variety)"}
knitr::include_graphics(
  here("figs", "manuscript", "learner_dp_utterance_variety.pdf")
  )
```


```{r, 'table-dp-utterance-variety'}
read_csv(here("tables", "dp_utterance_variety.csv"), col_types = cols(.default = "c")) %>% 
  mutate(Model = case_when(
    Model == "Utterance type" & Parameter == "Broad focus statement" ~ "Utterance type", 
    Model == "Utterance type" & Parameter != "Broad focus statement" ~ " ", 
    Model == "Variety" & Parameter == "Andalusian" ~ "Variety", 
    Model == "Variety" & Parameter != "Andalusian" ~ " " 
  )) %>% 
  knitr::kable(format = "pandoc", align = c(rep("l", 2), rep("r", 3)), 
    caption = "Summary of the posterior distribution modeling 
    d' as a function of question type or speaker variety. The table 
    includes posterior medians, the 95% HDI, and the maximum 
    probability of effect (MPE).",
    label = "table-dp-utterance-variety")
```



**Familiar vs. unfamiliar varieties**. At the beginning of the experimental session, participants responded to the prompt 'I am most familiar with Spanish from' and, using a drop-down window, made a selection from the following choices: I am not familiar with Spanish, Argentina, Bolivia, Chile, Colombia, Costa Rica, Cuba, Dominican Republic, Ecuador, El Salvador, Equatorial Guinea, Guatemala, Honduras, Mexico, Nicaragua, Panama, Paraguay, Peru, Philippines, Puerto Rico, Uruguay, Venezuela, Spain, and United States. 
These choices represent the countries/territories/commonwealths where Spanish is spoken as an official or co-official language with the exception of Andorra, Belize, Gibraltar, and the Philippines, which were not included by mistake. 
Table \@ref(tab:table-familiarity-summary) below summarizes the participants' responses to this question. 
Of note, participants overwhelmingly selected 'U.S. Spanish', followed by 'Mexico', 'Peninsular', and 'Not familiar'. 

```{r, 'table-familiarity-summary'}
familiarity_table %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r"), 
    caption = "Summary of participant self-reported familiarity with Spanish.",
    label = "table-familiarity-summary")
```

We did not pre-register a hypothesis regarding participant familiarity with Spanish. 
The following analysis is exploratory in nature. 
We analyzed the data from the participants who claimed to be most familiar with a Spanish variety that was included in our speaker varieties: Peninsular and Mexican Spanish (note: we make the assumption that 'Peninsular' is most closely associated with the Madrileño speaker). 
We coded the participants' responses to familiar versus unfamiliar varieties and fit a Bayesian logistic regression model to the data. 
The model was specified similar to previous models: 

$$
\begin{aligned}
\text{is_correct}_{ij} &\sim Bernoulli\left(p_{ij}, m_{ij}\right) \\
\text{logit}\left(p_{ij}\right) &= \beta_{0} + \beta_{1} * question\_type + \beta_{2} * Familiarity \\ 
 & \ \ \ \ \beta_{3} * question\_type * Familiarity
\end{aligned}
$$

We specified grouping variables for participant, speaker variety, and individual items. 
The models estimated varying slopes for the sentence type effect for each participant and the familiarity effect for each item. 
Again, we used the `0 + Intercept` syntax of `brms` and set weakly informative priors as follows: 

$$
\begin{aligned}
\beta  &\sim Normal(0, 1) \\
\sigma &\sim Cauchy(0, 0.2) \\
\rho   &\sim LKJcorr(1)
\end{aligned}
$$

In short, we find that, marginalizing over proficiency and empathy, participants were more accurate when responding to a familiar variety. 
This is true for all utterance types to some degree, but more clearly the case for questions (likely because responses to declarative utterances were near ceiling). 
Figure \@ref(fig:plot-learner-variety-familiarity) included in the manuscript illustrates the familiarity effect.
Table \@ref(tab:table-learner-variety-familiarity-model-summary) summarizes the model output. 
For convenience, we also provide the conditional effects of response accuracy in Table \@ref(tab:table-learner-variety-familiarity-conditional-effects). 

```{r, 'table-learner-variety-familiarity-model-summary'}
read_csv(here("tables", "learner_variety_match_response_model_summary.csv")) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r", "r", "r"), 
    caption = glue::glue("Summary of the posterior distribution modeling 
    response accuracy as a function of utterance type and 
    familiarity. The model only includes data from participants who claimed to 
    be familiar with Mexican (n =  {familiarity$Mexico$n_v}) and Peninsular 
    (n = {familiarity$Spain$n_v}) Spanish.
    The table includes posterior medians, the 95% HDI, the percentage of the 
    HDI within the ROPE, and the maximum probability of effect (MPE)."),
    label = "table-learner-variety-familiarity-model-summary")
```


```{r, 'table-learner-variety-familiarity-conditional-effects'}
read_csv(here("tables", "learner_variety_match_response_cond_effects.csv")) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r"), 
    caption = glue::glue("Conditional effects of response accuracy as a 
    function of sentence type and familiarity with the Spanish variety. 
    Values represent posterior medians along with the 95% HDI for unfamiliar 
    and familiar conditions, along with the posterior difference 
    (familiar - unfamiliar). The posterior predictive distribution is based on 
    data from participants who claimed to be familiar with Mexican 
    (n =  {familiarity$Mexico$n_v}) and Peninsular 
    (n = {familiarity$Spain$n_v}) Spanish."), 
    label = "table-learner-variety-familiarity-conditional-effects")
```





*Monolingual response accuracy*. In preparing our materials before official data collection, we piloted the 2AFC task and the auditory stimuli on monolingual Spanish speakers. 
The purpose of collecting this pilot data was to get an assessment of task difficulty---overall and as a function of speaker variety---and to have an idea what reasonable priors would be with regard to response times. 
From this pilot, we learned that, overall, monolingual speakers were least accuracy when responding to the Cuban variety, and to some degree the Puerto Rican variety as well. 
This finding led us to hypothesize that L2 learners would also have difficulties when responding to stimuli from the same varieties.
Figure \@ref(fig:plot-learner-native-accuracy) plots the monolingual accuracy data (right panel) next to the learner accuracy data (left panel). 
The same information is also provided in numeric form in Table \@ref(tab:table-learner-native-accuracy).

(ref:plot-learner-native-accuracy) Response accuracy as a function of group (L2 learner, monolingual Spanish speaker), speaker variety (Andalusian, Argentine, Chilean, Cuban, Madrileño, Mexican, Peruvian, Puerto Rican), and utterance type (broad focus statement, narrow focus statement, wh- question, y/n question). Points represent means of the raw data surrounded by the standard error of the mean.

```{r, 'plot-learner-native-accuracy', fig.cap="(ref:plot-learner-native-accuracy)"}
knitr::include_graphics(
  here("figs", "manuscript", "learner_native_accuracy.pdf")
  )
```

```{r, 'table-learner-native-accuracy'}
read_csv(here("tables", "learner_native_accuracy.csv")) %>% 
  mutate(Type = case_when(
    Variety != "Andalusian" & Type == "Broad focus statement" ~ " ", 
    Variety != "Andalusian" & Type == "Narrow focus statement" ~ " ", 
    Variety != "Andalusian" & Type == "Wh- question" ~ " ", 
    Variety != "Andalusian" & Type == "y/n question" ~ " ", 
    TRUE ~ Type
  )) %>% 
  knitr::kable(format = "pandoc", align = c(rep("l", 2), rep("r", 2)), 
    caption = "Response accuracy as a function of group (L2 learner, 
    monolingual Spanish speaker), speaker variety (Andalusian, Argentine, 
    Chilean, Cuban, Madrileño, Mexican, Peruvian, Puerto Rican), and 
    utterance type (broad focus statement, narrow focus statement, 
    wh- question, y/n question). Each column provides the mean and standard 
    error.",
    label = "table-learner-native-accuracy")
```

As a check on the low accuracy with the Cuban and Puerto Rican varieties, we decided to explore monolingual response accuracy further. 
To this end, we looked at the monolinguals' responses when they were presented with stimuli from their own variety, e.g., an Andalusian listener responding to stimuli from the Andalusian speaker. 
In our data, this implied a subset of Andalusian, Chilean, Cuban, Madrileño, Mexican, and Puerto Rican listeners.
Figure \@ref(fig:plot-variety-matched-native-accuracy) plots the variety-matched raw accuracy scores as a function of utterance type and Table \@ref(tab:table-variety-matched-native-accuracy) provides the same information in numeric form. 
Of note, all the monolinguals in our sample were at ceiling for all utterance types when responding to speakers from their own variety.
This is taken as evidence that the auditory stimuli are accurate representations of questions and statements for these varieties.

(ref:plot-variety-matched-native-accuracy) Variety-matched accuracy of monolingual listeners as a function of utterance type (broad focus statement, narrow focus statement, wh- question, y/n question). Points represent means of the raw data surrounded by the standard error of the mean.

```{r, 'plot-variety-matched-native-accuracy', fig.cap="(ref:plot-variety-matched-native-accuracy)"}
knitr::include_graphics(
  here("figs", "manuscript", "native_variety_matched_accuracy.pdf")
  )
```

```{r, 'table-variety-matched-native-accuracy'}
read_csv(here("tables", "variety_matched_native_accuracy.csv")) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r", "r"), 
    caption = "Variety-matched response accuracy as a function of utterance 
    type. Accuracy refers to the proportion of correct responses along with 
    the standard error of the mean.",
  label = "table-variety-matched-native-accuracy")
```



```{=openxml}
<w:p><w:r><w:br w:type="page"/></w:r></w:p>
```

## Auditory stimuli {#auditory-stimuli}

*Speakers*. The auditory stimuli consisted of eight varieties of Spanish: Cuban, Peninsular-Madrileño, Peninsular-Andalusian, Puerto Rican, Chilean, Argentine, Mexican, and Peruvian. 
The speakers from Argentina, Chile, Peru, and Spain are linguists. 
Table \@ref(tab:table-stimuli-descriptives) contains demographic information about the speakers. 

```{r, speakers}
tribble(
  ~'Country', ~'City/Variety', ~'Gender', ~'Age', 
  "Argentina", "Buenos Aires", "Male", 27, 
  "Chile", "Valparaíso", "Female", 42, 
  "Cuba", "Havana", "Female", 55, 
  "Mexico", "Mexico City", "Female", 30, 
  "Peru", "Lima", "Male", 30, 
  "Puerto Rico", "Ponce", "Female", 35, 
  "Spain", "Cádiz (Andalusia)", "Female", 35, 
  "Spain", "Madrid", "Female", 29
  ) %>% 
  knitr::kable(format = "pandoc", 
    caption = "Demographic information for the eight varieties of Spanish 
    represented in the auditory stimuli.",
    label = "table-stimuli-descriptives")
```


*Speech rate*. In order to evaluate the possibility that the speech rate of the talkers in our stimuli may have affected response accuracy, we calculated the articulation rate (syllables spoken per second during phonation time), average syllable duration (in milliseconds), and speech rate (number of syllables divided by total time) for all items (64 items &times; 8 speakers = `r 64 * 8` utterances). 
These values are provided in Table \@ref(tab:table-stimuli-sr). 

```{r}
#| label: speech-rate-table
mono_speech_rates_avg %>% 
  mutate(`Syllable duration` = round(`Avg. syllable duration` * 1000), 
    Variety = case_when(
      Variety == "Penninsular" ~ "Madrileño", 
      Variety == "Puertorican" ~ "Puerto Rican", 
      TRUE ~ .$Variety), 
    across(c("Articulation rate", "Speech rate"), specify_decimal, k = 2)) %>% 
  select(Variety, `Articulation rate`, `Syllable duration`, `Speech rate`) %>% 
  knitr::kable(format = "pandoc", align = c("l", "r", "r", "r"), 
  caption = "Average articulation rate (number of syllables divided by total 
  phonation time), syllables duration (in milliseconds), and speech rate (number 
  of syllable divided by total time) for each variety of the acoustic stimuli 
  presented to listeners.",
    label = "table-stimuli-sr")
```

Figure \@ref(fig:plot-sm-random-speech-rate) plots the posterior medians along with 66% and 95% HDI of standardized articulation rate for each variety. 
The plot shows that, generally, there was not a lot of variability between varieties. 
Though some of the slower varieties are also those in which we see higher response accuracy (compare with Figure \@ref(fig:plot-learner-accuracy-rt-by-speaker-variety)), that was not always the case. 
That is, some of the faster varieties also had high response accuracy, e.g., Mexican Spanish. 

(ref:plot-sm-random-speech-rate) Standardized articulation rate as a function of speaker variety. Points represent posterior medians along with 66% and 95% HDI. The value '0' on the horizontal axis represents the grand mean in the standardized space, which is equivalent to `r sr_grand_mean` syllables per second.

```{r, 'plot-sm-random-speech-rate', fig.cap="(ref:plot-sm-random-speech-rate)"}
knitr::include_graphics(
  here("figs", "manuscript", "sm_speech_rate.pdf")
  )
```


*Acoustic description*. In this subsection we provide examples of intonation contours for the four utterance types (broad focus state, narrow focus statement, wh- question, yes/no question) from the speakers of our eight varieties of Spanish (Cuban, Peninsular-Madrileño, Peninsular-Andalusian, Puerto Rican, Chilean, Argentine, Mexican, and Peruvian). 
Using the recordings, we generated figures that display the waveform, spectrogram, and fundamental frequency contours. 
The figure are accompanied with two annotation tiers: the orthographic tier and the tone tier. 
We use this information together to identify associations between tonal targets and specific structure within example utterances following the Autosegmental Metrical model [@pierrehumbert1980phonology]. 
We follow the conventions of the Spanish Tones and Break Indices (Sp_ToBI) and its revisions [@beckman2002intonation; @sosa2003notacion; @face2007rising; @vilaplana2008notacion]. 



Spectrograms \@ref(fig:plot-spectrogram-castilian)-\@ref(fig:plot-spectrogram-puertorican)

(ref:plot-spectrogram-castilian) Stuff they made me do.

```{r, 'plot-spectrogram-castilian', fig.cap="(ref:plot-spectrogram-castilian)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_castilian.pdf")
  )
```


(ref:plot-spectrogram-andalusian) Stuff they made me do.

```{r, 'plot-spectrogram-andalusian', fig.cap="(ref:plot-spectrogram-andalusian)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_andalusian.pdf")
  )
```


(ref:plot-spectrogram-argentine) Stuff they made me do.

```{r, 'plot-spectrogram-argentine', fig.cap="(ref:plot-spectrogram-argentine)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_argentine.pdf")
  )
```


(ref:plot-spectrogram-chilean) Stuff they made me do.

```{r, 'plot-spectrogram-chilean', fig.cap="(ref:plot-spectrogram-chilean)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_chilean.pdf")
  )
```


(ref:plot-spectrogram-cuban) Stuff they made me do.

```{r, 'plot-spectrogram-cuban', fig.cap="(ref:plot-spectrogram-cuban)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_cuban.pdf")
  )
```


(ref:plot-spectrogram-mexican) Stuff they made me do.

```{r, 'plot-spectrogram-mexican', fig.cap="(ref:plot-spectrogram-mexican)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_mexican.pdf")
  )
```


(ref:plot-spectrogram-peruvian) Stuff they made me do.

```{r, 'plot-spectrogram-peruvian', fig.cap="(ref:plot-spectrogram-peruvian)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_peruvian.pdf")
  )
```


(ref:plot-spectrogram-puertorican) Stuff they made me do.

```{r, 'plot-spectrogram-puertorican', fig.cap="(ref:plot-spectrogram-puertorican)"}
knitr::include_graphics(
    here("figs", "stimuli", "spectrogram_puertorican.pdf")
  )
```












\@ref(fig:plot-stimuli-pitch-contours)

```{=openxml}
<w:p><w:r><w:br w:type="page"/></w:r></w:p>
```

(ref:plot-stimuli-pitch-contours) Stuff they made me do.

```{r, 'plot-stimuli-pitch-contours', fig.cap="(ref:plot-stimuli-pitch-contours)"}
knitr::include_graphics(
    here("figs", "manuscript", "stimuli_pitch_contours.pdf")
  )
```




**Randomization check across participants**. For the purposes of our research questions, it was important that every participant be presented with stimuli from all of the Spanish varieties to which we had access. 
Recall that the 2AFC task contained 64 items, 16 of each utterance type. Using javascript we assigned each variety an equal probability of being selected in a given trial (0.125). 
To ensure that our randomization worked as planned (i.e., with each variety represented approximately equally across all trials and all participants), we calculated the average number of times each variety was presented in the data set (n = `r n_learners`, and `r nrow(learners)` trials). 
One can observe in Figure \@ref(fig:plot-sm-random-speaker-check) that this is indeed the case. 

(ref:plot-sm-random-speaker-check) Average number of tokens (&pm;1 SD) presented from each speaker variety across all 14,400 trials. The experiment was programmed such that each of the 8 varieties had an equal probability of being presented (`r 1/8 * 100`%) across 64 experimental trials.

```{r, 'plot-sm-random-speaker-check', fig.cap="(ref:plot-sm-random-speaker-check)"}
knitr::include_graphics(
  here("figs", "manuscript", "sm_random_speaker_check.pdf")
  )
```


*Items*. Table \@ref(tab:table-stimuli-items) provides a list of all of the target items used for each utterance type.

```{r}
#| label: print-stim

learners %>% 
  group_by(sentence_type, sentence) %>% 
  summarize(.groups = "drop") %>% 
  mutate(
    sentence = str_replace_all(sentence, "leia", "leía"), 
    sentence = str_replace_all(sentence, "comia", "comía"),
    sentence = str_replace_all(sentence, "nino", "niño"),
    sentence = str_replace_all(sentence, "rio", "río"),
    sentence = str_replace_all(sentence, "nina", "niña"),
    sentence = str_replace_all(sentence, "Maria", "María"),
    sentence = str_replace_all(sentence, "tia", "tía"),
    sentence = str_replace_all(sentence, "Cuando", "Cuándo"),
    sentence = str_replace_all(sentence, "Por que", "Por qué"),
    sentence = str_replace_all(sentence, "bebia", "bebía"),
    `Utterance type` = case_when(
      sentence_type == "declarative-broad-focus" ~ "Broad focus statement", 
      sentence_type == "declarative-narrow-focus" ~ "Narrow focus statement", 
      sentence_type == "interrogative-partial-wh" ~ "Wh- question", 
      sentence_type == "interrogative-total-yn" ~ "yes/no question"), 
    Item = sentence) %>% 
  mutate(Item = case_when(
    `Utterance type` == "Narrow focus statement" & 
      Item == "Ana lleva el abrigo" ~ "(¿Qué lleva Ana?) Ana lleva el abrigo",
    `Utterance type` == "Narrow focus statement" & 
      Item == "Daniel iba a Bolivia" ~ "(¿A dónde iba Daniel?) Daniel iba a Bolivia", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "David leía el libro" ~ "(¿Qué leía David?) David leía el libro", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "El bebe comía muy bien" ~ "(¿Cómo comía el bebé?) El bebe comía muy bien", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "El hombre mira la luna" ~ "(¿Qué mira el hombre?) El hombre mira la luna", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "El niño oye el río" ~ "(¿Qué oye el niño?) El niño oye el río", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Emilio ama la marcha" ~ "(¿Qué ama Emilio?) Emilio ama la marcha", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "La maestra vive en Paris" ~ "(¿Dónde vive la maestra?) La maestra vive en Paris", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "La niña lava el plato" ~ "(¿Qué lava la niña?) La niña lava el plato", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Manuela vende el carro" ~ "(¿Qué vende Manuela?) Manuela vende el carro", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "María bebe el vino" ~ "(¿Qué bebe María?) María bebe el vino", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Maríano habla del tiempo" ~ "(¿De qué habla Mariano?) Maríano habla del tiempo", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Marta abre el regalo" ~ "(¿Qué abre Marta?) Marta abre el regalo", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Mi madre come la fruta" ~ "(¿Qué come tu madre?) Mi madre come la fruta", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Mi novio viene del lago" ~ "(¿De dónde viene tu novio?) Mi novio viene del lago", 
    `Utterance type` == "Narrow focus statement" & 
      Item == "Mi tía odia la lluvia" ~ "(¿Qué odia tu tía?) Mi tía odia la lluvia", 
    TRUE ~ .$sentence)) %>% 
  mutate(
    Item = if_else(`Utterance type` %in% c("Wh- question", "yes/no question"), 
    glue("¿{.$Item}?"), .$Item)) %>% 
  arrange(`Utterance type`) %>% 
  transmute(
    `Utterance type` = case_when(
      sentence == "Ana lleva el abrigo" & sentence_type == "declarative-broad-focus" ~ .$`Utterance type`, 
      sentence == "Ana lleva el abrigo" & sentence_type == "declarative-narrow-focus" ~ .$`Utterance type`, 
      sentence == "Cuándo bebía el vino" & sentence_type == "interrogative-partial-wh" ~ .$`Utterance type`, 
      sentence == "Ana lleva el abrigo" & sentence_type == "interrogative-total-yn" ~ .$`Utterance type`, 
      TRUE ~ " "
    ), 
    Item, 
  ) %>% 
  knitr::kable(format = "pandoc", 
    caption = "Experimental items produced in auditory stimuli.",
    label = "table-stimuli-items")

```









```{=openxml}
<w:p><w:r><w:br w:type="page"/></w:r></w:p>
```

## Author contributions

(ref:plot-credit) Author contributions according to the CREDiT author roles taxonomy. Contributions are indicated as being substantial (dark diamonds) or moderate (light diamonds).

```{r, 'plot-credit', fig.cap="(ref:plot-credit)"}
knitr::include_graphics(
  here("figs", "project_contributors.pdf")
  )
```







```{=openxml}
<w:p><w:r><w:br w:type="page"/></w:r></w:p>
```

## Reproducibility information

**About this document**  

This document was written in RMarkdown using `papaja` [@R-papaja].

**Session info**  

```{r, 'session-info', comment=""}
devtools::session_info()$platform
as.data.frame(devtools::package_info())[, c(3, 8)]
```
